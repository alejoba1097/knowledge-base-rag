# ğŸ“š Knowledge Base RAG

A full-stack Retrieval-Augmented Generation (RAG) application that allows users to upload documents and ask questions about their content. The system extracts text from documents, generates embeddings, stores them in a vector database, and uses an LLM to provide contextual, source-grounded answers.

![RAG Knowledge Base](https://img.shields.io/badge/RAG-Knowledge%20Base-blue?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

---

## ğŸ› ï¸ Tech Stack

### Backend
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-121212?style=for-the-badge&logo=chainlink&logoColor=white)

### Frontend
![React](https://img.shields.io/badge/React-61DAFB?style=for-the-badge&logo=react&logoColor=black)
![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)
![Vite](https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white)

### Infrastructure
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![ChromaDB](https://img.shields.io/badge/ChromaDB-FF6F61?style=for-the-badge&logo=databricks&logoColor=white)

### ML & NLP
![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)
![Sentence Transformers](https://img.shields.io/badge/Sentence%20Transformers-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![Tesseract OCR](https://img.shields.io/badge/Tesseract-5C5C5C?style=for-the-badge&logo=google&logoColor=white)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚    Frontend     â”‚â”€â”€â”€â”€â–¶â”‚    Backend      â”‚â”€â”€â”€â”€â–¶â”‚    ChromaDB     â”‚
â”‚  React + Vite   â”‚     â”‚    FastAPI      â”‚     â”‚  Vector Store   â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚            â”‚            â”‚
                    â–¼            â–¼            â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚Tesseract â”‚ â”‚ Sentence â”‚ â”‚  LLM     â”‚
             â”‚   OCR    â”‚ â”‚Transformersâ”‚ â”‚(TinyLlama)â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The project follows **Clean Architecture** principles with clear separation of concerns:

- **Domain Layer**: Core business entities and repository interfaces
- **Application Layer**: Use cases (chat, upload document)
- **Infrastructure Layer**: External service implementations (ChromaDB, Sentence Transformers, Tesseract)
- **Interface Layer**: API controllers and schemas

---

## âœ¨ Features

- ğŸ“„ **Document Upload**: Upload PDF files and images
- ğŸ” **Text Extraction**: Automatic OCR using Tesseract for text extraction
- ğŸ§  **Semantic Search**: Vector embeddings with Sentence Transformers
- ğŸ’¬ **Chat Interface**: Ask questions and get contextual answers
- ğŸ“š **Source Attribution**: Answers include references to source documents
- ğŸ³ **Containerized**: Full Docker Compose setup for easy deployment
- ğŸ® **GPU Support**: NVIDIA GPU acceleration for faster inference

---

## ğŸš€ Getting Started

### Prerequisites

- [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/)
- NVIDIA GPU with CUDA support (optional, for GPU acceleration)
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) (if using GPU)

### Running with Docker Compose

1. **Clone the repository**
   ```bash
   git clone https://github.com/alejoba1097/knowledge-base-rag.git
   cd knowledge-base-rag
   ```

2. **Start all services**
   ```bash
   docker compose up --build
   ```

3. **Access the application**
   - Frontend: http://localhost:4173
   - Backend API: http://localhost:8000
   - API Docs: http://localhost:8000/docs

### Running without GPU

If you don't have an NVIDIA GPU, modify the `docker-compose.yml` to remove the GPU configuration:

```yaml
backend:
  build:
    context: .
    dockerfile: backend/Dockerfile
  environment:
    KB_CHROMA_HOST: chroma
    KB_CHROMA_PORT: 8000
    KB_CHROMA_COLLECTION_NAME: documents
    KB_RAG_MODEL_NAME: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ports:
    - "8000:8000"
  depends_on:
    - chroma
  # Remove the gpus section
```

---

## ğŸ”§ Local Development

### Backend

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Run the server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend

```bash
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

### ChromaDB (Vector Store)

```bash
docker run -d -p 8001:8000 ghcr.io/chroma-core/chroma:latest
```

---

## ğŸ“ Project Structure

```
knowledge-base-rag/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/app/
â”‚   â”‚   â”œâ”€â”€ application/       # Use cases
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”‚   â””â”€â”€ upload_document.py
â”‚   â”‚   â”œâ”€â”€ core/              # Configuration
â”‚   â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ domain/            # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ infrastructure/    # External services
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”œâ”€â”€ text_extraction/
â”‚   â”‚   â”‚   â””â”€â”€ vectorstores/
â”‚   â”‚   â”œâ”€â”€ interfaces/        # API layer
â”‚   â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPanel.tsx
â”‚   â”‚   â”‚   â””â”€â”€ UploadPanel.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â””â”€â”€ docker-compose.yml
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/upload` | Upload a document (PDF/image) |
| `POST` | `/chat` | Send a question and get an answer |
| `GET`  | `/docs` | OpenAPI documentation |

---

## âš™ï¸ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `KB_CHROMA_HOST` | ChromaDB host | `chroma` |
| `KB_CHROMA_PORT` | ChromaDB port | `8000` |
| `KB_CHROMA_COLLECTION_NAME` | Collection name | `documents` |
| `KB_RAG_MODEL_NAME` | LLM model name | `TinyLlama/TinyLlama-1.1B-Chat-v1.0` |

---

## ğŸ“ License

This project is licensed under the MIT License.

